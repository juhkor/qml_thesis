import numpy as np
import random
import os
import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.random import set_seed
import torch


labels = ['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']

classic_conf_matrix = [[144, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
                [0, 142, 4, 2, 1, 0, 2, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
                [0, 6, 161, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 4, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 4],
                [0, 3, 0, 151, 0, 3, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0, 3, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 2, 0, 0, 1, 1],
                [0, 2, 1, 0, 179, 6, 0, 0, 0, 0, 0, 6, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0],
                [1, 0, 0, 4, 8, 334, 0, 1, 0, 0, 1, 7, 0, 0, 0, 0, 0, 1, 11, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0],
                [0, 0, 1, 2, 0, 0, 341, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 6, 0, 0, 0, 0, 0, 0, 0],
                [0, 2, 0, 4, 0, 1, 0, 376, 4, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 4, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 1],
                [1, 0, 0, 1, 1, 0, 0, 1, 123, 8, 11, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
                [1, 0, 0, 1, 0, 0, 0, 1, 6, 111, 25, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
                [4, 0, 2, 2, 0, 0, 0, 1, 4, 10, 323, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2],
                [1, 1, 0, 0, 4, 5, 0, 0, 4, 1, 9, 325, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 0],
                [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 183, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],
                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 159, 0, 1, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
                [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 140, 3, 0, 2, 1, 0, 0, 4, 0, 3, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1],
                [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 316, 0, 1, 0, 3, 0, 3, 3, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1],
                [3, 0, 4, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 164, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
                [1, 0, 1, 1, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 13, 2, 2, 334, 5, 0, 1, 1, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0],
                [0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 9, 0, 1, 8, 3, 0, 2, 317, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3],
                [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 8, 0, 0, 7, 0, 0, 0, 0, 0, 351, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 6, 0, 0, 0, 1],
                [0, 0, 0, 1, 0, 0, 1, 10, 4, 0, 7, 0, 0, 1, 0, 0, 3, 1, 0, 6, 315, 2, 1, 2, 0, 0, 0, 1, 1, 2, 7, 0, 0, 0, 0],
                [2, 0, 0, 0, 1, 0, 0, 1, 1, 1, 3, 0, 0, 0, 4, 0, 2, 3, 0, 0, 2, 346, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0],
                [1, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 3, 7, 0, 4, 1, 0, 0, 2, 333, 0, 0, 3, 0, 5, 1, 0, 0, 0, 0, 0, 0],
                [1, 1, 1, 2, 0, 1, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 344, 1, 2, 0, 2, 0, 4, 0, 0, 0, 0, 1],
                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 3, 185, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2],
                [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 348, 0, 3, 0, 2, 0, 1, 1, 0, 1],
                [1, 0, 0, 2, 2, 4, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 5, 1, 1, 362, 0, 0, 1, 1, 0, 0, 0, 0],
                [0, 0, 2, 2, 0, 0, 3, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 350, 10, 6, 0, 0, 0, 0, 0],
                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 29, 139, 3, 0, 1, 1, 0, 0],
                [2, 0, 0, 3, 0, 1, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 1, 343, 0, 0, 0, 0, 4],
                [1, 0, 0, 3, 0, 0, 3, 0, 4, 1, 1, 3, 1, 4, 0, 1, 0, 0, 0, 14, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 316, 0, 0, 0, 0],
                [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 2, 0, 142, 0, 0, 7],
                [0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 3, 0, 0, 2, 1, 0, 0, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0],
                [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 16, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 1, 342, 1],
                [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 5, 2, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 3, 1, 0, 2, 0, 4, 0, 0, 0, 0, 372]]
                
qcnn_conf_matrix = [[140, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0],
            [0, 144, 3, 1, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],
            [0, 14, 154, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2],
            [0, 10, 0, 143, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 6, 0, 0, 6, 0],
            [0, 3, 1, 0, 164, 2, 1, 1, 0, 0, 3, 10, 0, 0, 0, 2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 2, 0, 0, 1, 0],
            [0, 2, 1, 0, 9, 324, 0, 1, 0, 0, 0, 11, 0, 0, 3, 0, 0, 2, 10, 0, 1, 3, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 1, 2],
            [0, 7, 0, 0, 1, 0, 331, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 5, 2, 5, 0, 0, 0, 0, 0],
            [1, 3, 6, 3, 0, 0, 1, 346, 4, 2, 3, 0, 0, 0, 0, 2, 0, 9, 0, 2, 9, 1, 8, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 2, 1, 0, 1, 122, 7, 7, 2, 0, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0],
            [1, 0, 1, 1, 0, 0, 0, 1, 4, 110, 27, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],
            [0, 1, 0, 0, 1, 0, 0, 1, 7, 10, 318, 1, 0, 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 3, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1],
            [0, 5, 2, 1, 3, 2, 2, 0, 0, 1, 6, 282, 0, 0, 1, 0, 0, 0, 20, 4, 1, 0, 1, 3, 0, 0, 0, 0, 0, 23, 0, 1, 1, 0, 1],
            [0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],
            [0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 3, 0, 149, 0, 0, 0, 0, 4, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
            [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 124, 5, 0, 5, 7, 0, 2, 7, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2],
            [0, 5, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 5, 306, 0, 0, 0, 2, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 9, 1],
            [1, 0, 5, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 4, 1, 157, 0, 0, 0, 1, 5, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],
            [0, 3, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 349, 6, 0, 0, 5, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
            [0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 16, 0, 0, 4, 5, 1, 1, 309, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 2, 0, 3],
            [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 6, 0, 0, 3, 0, 5, 0, 0, 0, 346, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 1],
            [0, 1, 5, 1, 0, 1, 1, 7, 2, 0, 3, 0, 0, 1, 3, 0, 0, 1, 0, 13, 316, 7, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0],
            [0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 2, 0, 1, 3, 349, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0],
            [0, 4, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 6, 1, 6, 0, 0, 0, 0, 345, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],
            [0, 1, 1, 4, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 342, 0, 5, 0, 1, 0, 1, 1, 0, 0, 0, 4],
            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 183, 0, 1, 1, 2, 3, 0, 0, 0, 0, 4],
            [1, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 6, 0, 335, 0, 4, 0, 2, 1, 0, 0, 4, 0],
            [0, 0, 0, 1, 5, 1, 1, 0, 1, 0, 4, 3, 0, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 6, 2, 1, 348, 0, 0, 2, 4, 0, 0, 0, 2],
            [0, 0, 2, 1, 0, 0, 4, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 1, 2, 0, 332, 18, 9, 0, 0, 0, 0, 1],
            [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 10, 160, 1, 0, 0, 0, 0, 0],
            [0, 0, 1, 4, 1, 0, 1, 0, 1, 2, 0, 7, 2, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 338, 0, 0, 0, 0, 1],
            [2, 0, 1, 0, 0, 0, 3, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 21, 5, 0, 1, 1, 0, 0, 1, 0, 2, 0, 318, 0, 1, 0, 0],
            [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 3, 1, 139, 0, 6, 7],
            [0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 178, 0, 0],
            [0, 7, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 351, 0],
            [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 4, 3, 2, 0, 2, 0, 7, 0, 1, 0, 1, 370]]


def reduce_labels(xs,qs,ys,to_drop):
    new_x=[]
    new_q=[]
    new_y=[]
    to_keep = []
    for name in labels:
        if name not in to_drop:
            idx = label_to_index(name)
            to_keep.append(idx)
    for x,q,y in zip(xs,qs,ys):
        idx = np.where(y == 1)
        name = index_to_label(idx[0][0])
        if name not in to_drop:
            new_x.append(x)
            new_q.append(q)
            new_y.append(y)
        
    new_y = np.array(new_y)
    new_y = new_y[:,to_keep]
    return np.array(new_x),np.array(new_q),new_y
    
    
def label_to_index(word):
    # Return the position of the word in labels
    return torch.tensor(labels.index(word))


def index_to_label(index):
    # Return the word corresponding to the index in labels
    # This is the inverse of label_to_index
    return labels[index]


def full_window():
    x_valid = np.load('equal_x_valid.npy')
    q_valid = np.load('equal_q_valid.npy')
    y_valid = np.load('equal_y_valid.npy')

    return x_valid,q_valid,y_valid

x_valid,q_valid,y_valid = full_window()
x_valid = x_valid[0:10000,:,:,:]
y_valid = y_valid[0:10000,:]

classic_conf_matrix = np.array(classic_conf_matrix)
qcnn_conf_matrix = np.array(qcnn_conf_matrix)

diagonal = np.diag(classic_conf_matrix)
qdiagonal = np.diag(qcnn_conf_matrix)

column_sums = np.sum(classic_conf_matrix, axis=0)
row_sums = np.sum(classic_conf_matrix, axis=1)
qcolumn_sums = np.sum(qcnn_conf_matrix, axis=0)
qrow_sums = np.sum(qcnn_conf_matrix, axis=1)

column_sums -= diagonal
row_sums -= diagonal
qcolumn_sums -= qdiagonal
qrow_sums -= qdiagonal

print('Classic false positive',column_sums,sum(column_sums))
print('Quantum false positive',qcolumn_sums,sum(qcolumn_sums))
print('Combined false positives',column_sums+qcolumn_sums)

cerrors = column_sums+row_sums
ctotal = column_sums+row_sums+diagonal
qerror = qcolumn_sums+qrow_sums
qtotal = qcolumn_sums+qrow_sums+qdiagonal

total_errors = (cerrors+qerror) / (cerrors+qerror+ctotal+qtotal)
min_error = min(total_errors)
min_id = np.where(total_errors == min_error)[0][0]
to_drop = [labels[min_id]]

x_valid, q_valid, y_valid = reduce_labels(x_valid, q_valid, y_valid, to_drop)


