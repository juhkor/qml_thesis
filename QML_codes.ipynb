{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm4aCQp_n5dd"
      },
      "source": [
        "# 1. Quantum machine learning, masters thesis source code.\n",
        "Sources for original codes are:\n",
        "* https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/63ef278c9730746362d08162a440df77/speech_command_classification_with_torchaudio_tutorial.ipynb\n",
        "* https://github.com/huckiyang/QuantumSpeech-QCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKiVmhI5TelQ"
      },
      "source": [
        "# 2. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u46kpQPtn3eT"
      },
      "outputs": [],
      "source": [
        "!pip install pydub torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvma096dTq4e"
      },
      "source": [
        "# 3. Prepare SpeechCommands dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyPXmkpKqNnR"
      },
      "outputs": [],
      "source": [
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(\"./\", download=True)\n",
        "\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n",
        "\n",
        "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
        "train_set = SubsetSC(\"training\")\n",
        "test_set = SubsetSC(\"testing\")\n",
        "\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n",
        "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctaXwnxa2OfE"
      },
      "source": [
        "# 4. Formatting of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG4cQXTC2Q6z"
      },
      "outputs": [],
      "source": [
        "new_sample_rate = 8000\n",
        "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "transformed = transform(waveform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr4UHf9c4Wb5"
      },
      "source": [
        "# 5. Encoding of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zXQv-8g4YXb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels  = np.load('/datasets/new_labels.npy')\n",
        "labels = labels.tolist()\n",
        "\n",
        "def label_to_index(word):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "def index_to_label(index):\n",
        "    # Return the word corresponding to the index in labels\n",
        "    # This is the inverse of label_to_index\n",
        "    return labels[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhTsYGF52pi0"
      },
      "source": [
        "# 6. Quantum CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKPLw3pWd4pp"
      },
      "outputs": [],
      "source": [
        "!pip install pennylane\n",
        "!pip install qiskit\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "import qiskit\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import time as ti\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "from keras.utils.layer_utils import count_params\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import RandomLayers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers  import Conv2D, MaxPooling2D, Dense, Flatten, GRU, BatchNormalization, Conv1D, Dropout, Bidirectional, MaxPooling1D, Input, Lambda, TimeDistributed, Activation\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "from tensorflow.math import confusion_matrix\n",
        "from tensorflow.random import set_seed\n",
        "\n",
        "\n",
        "## Local Definition \n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsitftMibrd9"
      },
      "source": [
        "# 7. Limited dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1wF8baLbyjm"
      },
      "outputs": [],
      "source": [
        "reduced_labels = ['left', 'go', 'yes', 'down', 'up', 'on', 'right', 'no', 'off', 'stop']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9WEFUrJC5Ug"
      },
      "source": [
        "# 8. Mount Google drive to colab for saving the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy2H8EZtC35i"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9WfGQUHluTW"
      },
      "source": [
        "# 9. LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-4WdXpU3O4l"
      },
      "outputs": [],
      "source": [
        "def attrnn_Model(x_in, labels, ablation = False, params = 64, divider = 1):\n",
        "    # simple LSTM\n",
        "    rnn_func = L.LSTM\n",
        "    # Restrict parameter amount\n",
        "    use_Unet = True\n",
        "\n",
        "    if len(x_in.shape) >= 3:\n",
        "        h_feat,w_feat,ch_size = x_in.shape\n",
        "        inputs = keras.layers.Input(shape=(h_feat, w_feat, ch_size))\n",
        "    else:\n",
        "        h_feat, w_feat = x_in.shape\n",
        "        inputs = keras.layers.Input(shape=(h_feat, w_feat))\n",
        "\n",
        "    inputs = L.Input(shape=(h_feat, w_feat, ch_size))\n",
        "\n",
        "    if ablation == True:\n",
        "        x = L.Conv2D(4, (1, 1), strides=(2, 2), activation='relu', padding='same', name='abla_conv')(inputs)\n",
        "        x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
        "    else:\n",
        "        x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(inputs)\n",
        "\n",
        "    # note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
        "    # we would rather have it the other way around for LSTMs\n",
        "    x = L.Permute((2, 1, 3))(x)\n",
        "\n",
        "    if use_Unet == True:\n",
        "        x = L.Conv2D(16//divider, (5, 1), activation='relu', padding='same')(x)\n",
        "        up = L.BatchNormalization()(x)\n",
        "        x = L.Conv2D(32//divider, (5, 1), activation='relu', padding='same')(up)\n",
        "        x = L.BatchNormalization()(x)\n",
        "        x = L.Conv2D(16//divider, (5, 1), activation='relu', padding='same')(x)\n",
        "        down = L.BatchNormalization()(x)\n",
        "        merge = L.Concatenate(axis=3)([up,down])\n",
        "        x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(merge)\n",
        "        x = L.BatchNormalization()(x)\n",
        "    else:\n",
        "        x = L.Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
        "        x = L.BatchNormalization()(x)\n",
        "        x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
        "        x = L.BatchNormalization()(x)\n",
        "\n",
        "    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
        "    # Classical model has significantly more parameters here\n",
        "    x = L.Bidirectional(rnn_func(params//divider, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "    x = L.Bidirectional(rnn_func(64//divider, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]\n",
        "\n",
        "    xFirst = L.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
        "    query = L.Dense(128//divider)(xFirst)\n",
        "    #query = L.Dense(126)(xFirst)\n",
        "\n",
        "    # dot product attention\n",
        "    attScores = L.Dot(axes=[1, 2])([query, x])\n",
        "    attScores = L.Softmax(name='attSoftmax')(attScores)  # [b_s, seq_len]\n",
        "\n",
        "    # rescale sequence\n",
        "    attVector = L.Dot(axes=[1, 1])([attScores, x])  # [b_s, vec_dim]\n",
        "\n",
        "    x = L.Dense(64//divider, activation='relu')(attVector)\n",
        "    x = L.Dense(32//divider)(x)\n",
        "\n",
        "    output = L.Dense(len(labels), activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output, name='Attn-BiLSTM')\n",
        "    model.compile(\n",
        "        optimizer=SGD(learning_rate=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "        #optimizer=SGD(learning_rate=0.02, decay=1e-6, momentum=0.1, nesterov=True, clipnorm=5),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9KLO4QO3djn"
      },
      "source": [
        "# 10. Mel spectrogram generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4PMHHYn3l16"
      },
      "outputs": [],
      "source": [
        "def gen_mel(labels, train_audio_path, sr, port):\n",
        "    all_wave = []\n",
        "    all_label = []\n",
        "    #Original values\n",
        "    #win_size = 1024\n",
        "    #hop = 128\n",
        "    win_size = 400\n",
        "    hop = 300\n",
        "    for num, wav in enumerate(train_audio_path, 0):\n",
        "        if num % port ==0:   # take 1/port samples\n",
        "            # Test same sample ratio as in classical case\n",
        "            if sr == 8000:\n",
        "                audio_arr = np.array(transform(wav[0]))\n",
        "            else:\n",
        "                audio_arr = np.array(wav[0])\n",
        "            \n",
        "            shape = audio_arr.shape\n",
        "            if(shape[1] == sr and wav[2] in labels):\n",
        "                audio_arr = audio_arr.reshape(sr)\n",
        "                mel_feat = librosa.feature.melspectrogram(audio_arr, sr=sr, n_fft=win_size, hop_length=hop, power=1.0, n_mels=60, fmin=40.0, fmax=sr/2)\n",
        "                all_wave.append(np.expand_dims(mel_feat, axis=2))\n",
        "                all_label.append(wav[2])\n",
        "    #print(all_label)\n",
        "    return all_wave, all_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ti0sx73gko"
      },
      "source": [
        "# 11. Quantum circuit and QCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu4OyGUD3que"
      },
      "outputs": [],
      "source": [
        "n_w = 4 # numbers of wires def 4\n",
        "noise_mode = False # for running at QPU\n",
        "\n",
        "if  noise_mode == True:\n",
        "    dev = qml.device('qiskit.aer', wires= n_w, noise_model=noise_model)\n",
        "else:\n",
        "    dev = qml.device(\"default.qubit\", wires= n_w)\n",
        "\n",
        "n_layers = 1\n",
        "\n",
        "# Random circuit parameters\n",
        "#rand_params = np.random.uniform(high= 2 * np.pi, size=(n_layers, n_w)) # def 2, n_w = 4\n",
        "rand_params = np.array([[3.48469964, 4.89657317, 3.11940734, 2.06955704]])\n",
        "\n",
        "params = [[0.04439891,0.14490549,3.29725643],\n",
        "          [2.51240058,0.29320901,6.11828637],\n",
        "          [1.46254547,0.56929702,3.88543389],\n",
        "          [2.40307956,6.17782186,2.93275775]]\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(phi=None):\n",
        "    # Encoding of 4 classical input values\n",
        "    for j in range(n_w):\n",
        "        qml.RY(np.pi * phi[j], wires=j)\n",
        "\n",
        "    # Random quantum circuit\n",
        "    RandomLayers(rand_params, wires=list(range(n_w)))\n",
        "\n",
        "    # Measurement producing 4 classical output values\n",
        "    return [qml.expval(qml.PauliZ(j)) for j in range(n_w)]\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit2(phi):\n",
        "    for j in range(n_w):\n",
        "        qml.RY(np.arctan(phi[j]), wires=j)\n",
        "        qml.RZ(np.arctan(phi[j]**2), wires=j)\n",
        "\n",
        "    qml.CNOT(wires=[0,1])\n",
        "    qml.CNOT(wires=[1,2])\n",
        "    qml.CNOT(wires=[2,3])\n",
        "    qml.CNOT(wires=[3,0])\n",
        "\n",
        "    for j in range(n_w):\n",
        "        x,y,z = params[j]\n",
        "        qml.Rot(x,y,z, wires=j)\n",
        "    \n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "    \n",
        "def quanv(image, kr):\n",
        "    h_feat, w_feat, ch_n = image.shape\n",
        "    \"\"\"Convolves the input speech with many applications of the same quantum circuit.\"\"\"\n",
        "    out = np.zeros((h_feat//kr, w_feat//kr, n_w))\n",
        "\n",
        "    # Loop over the coordinates of the top-left pixel of squares\n",
        "    for j in range(1, h_feat, kr):\n",
        "        for k in range(1, w_feat, kr):\n",
        "            # Process a squared 3x3 region of the image with a quantum circuit\n",
        "            if kr == 3:\n",
        "                q_results = circuit(# kernel 3 \n",
        "                    phi=[image[j, k, 0], image[j, k + 1, 0], image[j, k + 2, 0],\n",
        "                         image[j + 1, k, 0], image[j + 1, k + 1, 0], image[j + 1, k +2 , 0],\n",
        "                         image[j+2, k, 0], image[j+2, k+1, 0], image[j+2, k+2, 0]])\n",
        "            # Process a squared 2x2 region of the image with a quantum circuit\n",
        "            else:\n",
        "                q_results = circuit(# Kernel 2\n",
        "                    phi=[image[j-1, k-1, 0], image[j-1, k, 0],\n",
        "                         image[j, k-1, 0], image[j, k, 0]])\n",
        "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
        "            for c in range(n_w):\n",
        "                out[j // kr, k // kr, c] = q_results[c]\n",
        "    return out\n",
        "\n",
        "def quanv2(image, kr):\n",
        "    h_feat, w_feat, ch_n = image.shape\n",
        "    \"\"\"Convolves the input speech with many applications of the same quantum circuit.\"\"\"\n",
        "    out = np.zeros((h_feat//kr, w_feat//kr, ch_n))\n",
        "\n",
        "    # Loop over the coordinates of the top-left pixel of squares\n",
        "    for j in range(1, h_feat, kr):\n",
        "        for k in range(1, w_feat, kr):\n",
        "            # Process a squared 3x3 region of the image with a quantum circuit\n",
        "            q_results = circuit2(\n",
        "                phi=[image[j-1, k-1, 0], image[j-1, k, 0],\n",
        "                      image[j, k-1, 0], image[j, k, 0]])\n",
        "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
        "            out[j // kr, k // kr, 0] = q_results \n",
        "            \n",
        "    return out\n",
        "\n",
        "def gen_qspeech(x_train, x_valid, kr): # kernal size = 2x2 or 3x3\n",
        "    #q_train = []\n",
        "    #q_train = np.load('/datasets/q_trainFULL_ALTKERN.npy')\n",
        "    #q_train = np.load('/datasets/q_trainTIME_TEST.npy')\n",
        "    q_train = np.load('/datasets/q_trainTIME_TEST_kernel2.npy')\n",
        "    q_train = q_train.tolist()\n",
        "    print(\"Quantum pre-processing of train Speech:\")\n",
        "    for idx, img in enumerate(x_train):\n",
        "        print(\"\\r{}/{}        \".format(idx + 1, len(x_train)),end='')\n",
        "        #q_train.append(quanv(img, kr))\n",
        "        q_train.append(quanv2(img, kr))\n",
        "    \n",
        "    q_train = np.asarray(q_train)\n",
        "    \n",
        "    #q_valid = np.load('/datasets/q_validFULL_ALTKERN.npy')\n",
        "    #q_valid = np.load('/datasets/q_validTIME_TEST.npy')\n",
        "    q_valid = np.load('/datasets/q_validTIME_TEST_kernel2.npy')\n",
        "    q_valid = q_valid.tolist()\n",
        "    #q_valid =[]\n",
        "    print(\"\\nQuantum pre-processing of test Speech:\")\n",
        "    for idx, img in enumerate(x_valid):\n",
        "        print(\"\\r{}/{}        \".format(idx + 1, len(x_valid)), end=\"\")\n",
        "        #q_valid.append(quanv(img, kr))\n",
        "        q_valid.append(quanv2(img, kr))\n",
        "    \n",
        "    q_valid = np.asarray(q_valid)\n",
        "    #np.save('/datasets/q_trainTIME_TEST.npy',q_train)\n",
        "    #np.save('/datasets/q_validTIME_TEST.npy',q_valid)\n",
        "\n",
        "    np.save('/datasets/q_trainTIME_TEST_kernel2.npy',q_train)\n",
        "    np.save('/datasets/q_validTIME_TEST_kernel2.npy',q_valid)\n",
        "    \n",
        "    return q_train, q_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiuyFwYQDzrx"
      },
      "source": [
        "# 12. Original kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "FqYjMNV6cPr2",
        "outputId": "cb7da394-0fdd-4a72-e298-0f6c9d252e0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The datapath rcparam was deprecated in Matplotlib 3.2.1 and will be removed two minor releases later.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<Figure size 576x360 with 1 Axes>,\n",
              " <matplotlib.axes._axes.Axes at 0x7ff5637fe2b0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "qml.draw_mpl(circuit, expansion_strategy=\"device\")(np.array([0,1,1,0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5m3Mh68D8I4"
      },
      "source": [
        "# 13. Alternative kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "5B3FEGeNlveq",
        "outputId": "8e17f821-5519-4d7e-f698-765886c8d2e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The datapath rcparam was deprecated in Matplotlib 3.2.1 and will be removed two minor releases later.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n",
            "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: \n",
            "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = other[key]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<Figure size 720x360 with 1 Axes>,\n",
              " <matplotlib.axes._axes.Axes at 0x7ff4ecdde9d0>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "qml.draw_mpl(circuit2, expansion_strategy=\"device\")(np.array([0,1,1,0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE86hgD8pcOE"
      },
      "source": [
        "# 14. Classical convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7WmacdPkivv"
      },
      "outputs": [],
      "source": [
        "def kernel(phi):\n",
        "    # Classical kernel\n",
        "    kern = [1,0,0,1]\n",
        "    sum = 0;\n",
        "    for i,j in zip(kern,phi):\n",
        "        sum += i * j\n",
        "\n",
        "    return sum\n",
        "\n",
        "def conv(image, kr):\n",
        "    h_feat, w_feat, ch_n = image.shape\n",
        "    \"\"\"Classic convolution\"\"\"\n",
        "    out = np.zeros((h_feat//kr, w_feat//kr, ch_n))\n",
        "\n",
        "    # Loop over the coordinates of the top-left pixel of squares\n",
        "    for j in range(1, h_feat, kr):\n",
        "        for k in range(1, w_feat, kr):\n",
        "            result = kernel(\n",
        "                phi=[image[j-1, k-1, 0], image[j-1, k, 0],\n",
        "                      image[j, k-1, 0], image[j, k, 0]])\n",
        "            # Assign expectation values to output pixel (j/2, k/2)\n",
        "            out[j // kr, k // kr, 0] = result\n",
        "            \n",
        "    return out\n",
        "\n",
        "def gen_speech(x_train, x_valid, kr):\n",
        "    #c_train = np.load('/datasets/c_trainFULL.npy')\n",
        "    c_train = np.load('/datasets/c_trainTIME_TEST.npy')\n",
        "    c_train = c_train.tolist()\n",
        "    #c_train = []\n",
        "    print(\"Classical pre-processing of train Speech:\")\n",
        "    for idx, img in enumerate(x_train):\n",
        "        print(\"\\r{}/{}        \".format(idx + 1, len(x_train)),end='')\n",
        "        c_train.append(conv(img, kr))\n",
        "    \n",
        "    c_train = np.asarray(c_train)\n",
        "    \n",
        "    #c_valid = np.load('/datasets/c_validFULL.npy')\n",
        "    c_valid = np.load('/datasets/c_validTIME_TEST.npy')\n",
        "    c_valid = c_valid.tolist()\n",
        "    #c_valid =[]\n",
        "    print(\"\\nClassical pre-processing of test Speech:\")\n",
        "    for idx, img in enumerate(x_valid):\n",
        "        print(\"\\r{}/{}        \".format(idx + 1, len(x_valid)), end=\"\")\n",
        "        c_valid.append(conv(img, kr))\n",
        "    \n",
        "    c_valid = np.asarray(c_valid)\n",
        "    \n",
        "    np.save('/datasets/c_trainTIME_TEST.npy',c_train)\n",
        "    np.save('/datasets/c_validTIME_TEST.npy',c_valid)\n",
        "\n",
        "    return c_train, c_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e-HsngY3ZV-"
      },
      "source": [
        "# 15. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA0NQks_2uD1"
      },
      "outputs": [],
      "source": [
        "START = 0\n",
        "END = 10\n",
        "SR = 16000\n",
        "# take 1/port samples\n",
        "PORT = 1\n",
        "kr = 2\n",
        "# Change kr to 1 to tests affect of stride 1\n",
        "#kr = 1\n",
        "\n",
        "def gen_train(labels, train_audio_path, sr, port):\n",
        "    all_wave, all_label = gen_mel(labels, train_audio_path, sr, port)\n",
        "\n",
        "    label_enconder = LabelEncoder()\n",
        "    y = label_enconder.fit_transform(all_label)\n",
        "    classes = list(label_enconder.classes_)\n",
        "    y = keras.utils.to_categorical(y, num_classes=len(labels))\n",
        "\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)\n",
        "    h_feat, w_feat, _ = x_train[0].shape\n",
        "    \n",
        "    print(\"===== Shape\", h_feat, w_feat)\n",
        "\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "def gen_quanv(x_train, x_valid, kr):\n",
        "    print(\"Kernel = \", kr)\n",
        "    q_train, q_valid = gen_qspeech(x_train, x_valid, kr)\n",
        "\n",
        "    return q_train, q_valid\n",
        "\n",
        "def gen_conv(x_train, x_valid, kr):\n",
        "    print(\"Kernel = \", kr)\n",
        "    c_train, c_valid = gen_speech(x_train, x_valid, kr)\n",
        "\n",
        "    return c_train, c_valid\n",
        "\n",
        "def save_mel(x_train, x_valid, y_train, y_valid):\n",
        "    np.save('/datasets/x_train.npy',x_train)\n",
        "    np.save('/datasets/x_valid.npy',x_valid)\n",
        "    np.save('/datasets/y_train.npy',y_train)\n",
        "    np.save('/datasets/y_valid.npy',y_valid)\n",
        "\n",
        "def load_mel():\n",
        "    x_train = np.load('/datasets/equal_x_train.npy')\n",
        "    x_valid = np.load('/datasets/equal_x_valid.npy')\n",
        "    y_train = np.load('/datasets/equal_y_train.npy')\n",
        "    y_valid = np.load('/datasets/equal_y_valid.npy')\n",
        "\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "def load_mel_FULL():\n",
        "    x_train = np.load('/datasets/x_trainFULL.npy')\n",
        "    x_valid = np.load('/datasets/x_validFULL.npy')\n",
        "    y_train = np.load('/datasets/y_trainFULL.npy')\n",
        "    y_valid = np.load('/datasets/y_validFULL.npy')\n",
        "\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "def load_quanv():\n",
        "    q_train = np.load('/datasets/equal_q_train.npy')\n",
        "    q_valid = np.load('/datasets/equal_q_valid.npy')\n",
        "\n",
        "    return q_train, q_valid\n",
        "\n",
        "def load_quanv_FULL():\n",
        "    q_train = np.load('/datasets/q_trainFULL_ALTKERN.npy')\n",
        "    q_valid = np.load('/datasets/q_validFULL_ALTKERN.npy')\n",
        "\n",
        "    return q_train, q_valid\n",
        "\n",
        "def load_conv():\n",
        "    c_train = np.load('/datasets/c_trainFULL.npy')\n",
        "    c_valid = np.load('/datasets/c_validFULL.npy')\n",
        "\n",
        "    return c_train, c_valid\n",
        "\n",
        "#dataset = train_set+test_set\n",
        "#x_train, x_valid, y_train, y_valid = gen_train(labels, dataset, SR, PORT)\n",
        "#save_mel(x_train, x_valid, y_train, y_valid)\n",
        "x_train, x_valid, y_train, y_valid = load_mel_FULL()\n",
        "#print(x_train.shape,x_valid.shape,y_train.shape,y_valid.shape)\n",
        "#q_train, q_valid = load_quanv_FULL()\n",
        "#c_train, c_valid = load_conv()\n",
        "#equal_q_train, equal_q_valid = load_quanv()\n",
        "\n",
        "#START = q_valid.shape[0]\n",
        "#END = START+10\n",
        "\n",
        "c_train = []\n",
        "c_valid = []\n",
        "c_train = np.asarray(c_train)\n",
        "c_valid = np.asarray(c_valid)\n",
        "np.save('/datasets/c_trainTIME_TEST.npy',c_train)\n",
        "np.save('/datasets/c_validTIME_TEST.npy',c_valid)\n",
        "print(c_train.shape,c_valid.shape)\n",
        "\n",
        "'''\n",
        "q_train = []\n",
        "q_valid = []\n",
        "q_train = np.asarray(q_train)\n",
        "q_valid = np.asarray(q_valid)\n",
        "#np.save('/datasets/q_trainTIME_TEST.npy',q_train)\n",
        "#np.save('/datasets/q_validTIME_TEST.npy',q_valid)\n",
        "np.save('/datasets/q_trainTIME_TEST_kernel2.npy',q_train)\n",
        "np.save('/datasets/q_validTIME_TEST_kernel2.npy',q_valid)\n",
        "print(q_train.shape,q_valid.shape)\n",
        "'''\n",
        "\n",
        "start = ti.time()\n",
        "\n",
        "while(END<=50):\n",
        "    #q_train, q_valid = gen_quanv(x_train[START:END,:,:,:], x_valid[START:END,:,:,:], kr)\n",
        "    c_train, c_valid = gen_conv(x_train[START:END,:,:,:], x_valid[START:END,:,:,:], kr)\n",
        "    print()\n",
        "    #print(q_train.shape,q_valid.shape)\n",
        "    print(c_train.shape,c_valid.shape)\n",
        "    #START = q_valid.shape[0]\n",
        "    START = c_train.shape[0]\n",
        "    END = START+10\n",
        "    #END = 10001\n",
        "\n",
        "spent = ti.time() - start\n",
        "print('time spent',spent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_0i1BEaDahq"
      },
      "source": [
        "# 16. Functions to load premade datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaCA09xCUKQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Datasets with full Mel spectrogram window\n",
        "def time_tests():\n",
        "    x_train = np.load('/datasets/x_trainFULL.npy')\n",
        "    x_valid = np.load('/datasets/x_validFULL.npy')\n",
        "    c_train = np.load('/datasets/c_trainTIME_TEST.npy')\n",
        "    c_valid = np.load('/datasets/c_validTIME_TEST.npy')\n",
        "    q_train = np.load('/datasets/q_trainTIME_TEST.npy')\n",
        "    q_valid = np.load('/datasets/q_validTIME_TEST.npy')\n",
        "    q_train2 = np.load('/datasets/q_trainTIME_TEST_kernel2.npy')\n",
        "    q_valid2 = np.load('/datasets/q_validTIME_TEST_kernel2.npy')\n",
        "    y_train = np.load('/datasets/y_trainFULL.npy')\n",
        "    y_valid = np.load('/datasets/y_validFULL.npy')\n",
        "\n",
        "    return x_train[0:50,:,:,:],x_valid[0:50,:,:,:],c_train,c_valid,q_train,q_valid,q_train2,q_valid2,y_train[0:50,:],y_valid[0:50,:]\n",
        "\n",
        "def reduced():\n",
        "    x_train = np.load('/datasets/x_trainREDUCED.npy')\n",
        "    x_valid = np.load('/datasets/x_validREDUCED.npy')\n",
        "    q_train = np.load('/datasets/q_trainREDUCED.npy')\n",
        "    q_valid = np.load('/datasets/q_validREDUCED.npy')\n",
        "    y_train = np.load('/datasets/y_trainREDUCED.npy')\n",
        "    y_valid = np.load('/datasets/y_validREDUCED.npy')\n",
        "\n",
        "    return x_train,x_valid,q_train,q_valid,y_train,y_valid\n",
        "\n",
        "def full_window():\n",
        "    x_train = np.load('/datasets/x_trainFULL.npy')\n",
        "    x_valid = np.load('/datasets/x_validFULL.npy')\n",
        "    q_train = np.load('/datasets/q_trainFULL.npy')\n",
        "    q_valid = np.load('/datasets/q_validFULL.npy')\n",
        "    y_train = np.load('/datasets/y_trainFULL.npy')\n",
        "    y_valid = np.load('/datasets/y_validFULL.npy')\n",
        "\n",
        "    return x_train,x_valid,q_train,q_valid,y_train,y_valid\n",
        "\n",
        "\n",
        "# Datasets with smaller Mel spectrogram window\n",
        "def smaller_window():\n",
        "    q_train = np.load('/datasets/q_train.npy')\n",
        "    q_valid = np.load('/datasets/q_valid.npy')\n",
        "    x_train = np.load('/datasets/x_train.npy')\n",
        "    x_valid = np.load('/datasets/x_valid.npy')\n",
        "    y_train = np.load('/datasets/y_train.npy')\n",
        "    y_valid = np.load('/datasets/y_valid.npy')\n",
        "\n",
        "    return x_train,x_valid,q_train,q_valid,y_train,y_valid\n",
        "\n",
        "\n",
        "# Datasets with equalized distribution. 134 samples / class\n",
        "def equalized():\n",
        "    equal_q_train = np.load('/datasets/equal_q_train.npy')\n",
        "    equal_q_valid = np.load('/datasets/equal_q_valid.npy')\n",
        "    equal_x_train = np.load('/datasets/equal_x_train.npy')\n",
        "    equal_x_valid = np.load('/datasets/equal_x_valid.npy')\n",
        "    equal_y_train = np.load('/datasets/equal_y_train.npy')\n",
        "    equal_y_valid = np.load('/datasets/equal_y_valid.npy')\n",
        "\n",
        "    return equal_x_train,equal_x_valid,equal_q_train,equal_q_valid,equal_y_train,equal_y_valid\n",
        "\n",
        "# Datasets with classical convolution\n",
        "def classic_conv():\n",
        "    c_train = np.load('/datasets/c_train.npy')\n",
        "    c_valid = np.load('/datasets/c_valid.npy')\n",
        "    q_train = np.load('/datasets/q_trainFULL_ALTKERN.npy')\n",
        "    q_valid = np.load('/datasets/q_validFULL_ALTKERN.npy')\n",
        "    y_train = np.load('/datasets/y_trainFULL.npy')\n",
        "    y_valid = np.load('/datasets/y_validFULL.npy')\n",
        "\n",
        "    return c_train,c_valid,q_train,q_valid,y_train,y_valid\n",
        "\n",
        "#x_train,x_valid,q_train,q_valid,y_train,y_valid = full_window()\n",
        "#x_train,x_valid,q_train,q_valid,y_train,y_valid = classic_conv()\n",
        "#x_train,x_valid,q_train,q_valid,y_train,y_valid = smaller_window()\n",
        "#x_train,x_valid,q_train,q_valid,y_train,y_valid = equalized()\n",
        "#x_train,x_valid,c_train,c_valid,q_train,q_valid,q_train2,q_valid2,y_train,y_valid = time_tests()\n",
        "x_train,x_valid,q_train,q_valid,y_train,y_valid = reduced()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siKL6qbKZzaq"
      },
      "source": [
        "# 17. Function to reduce number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5V2gL7vZyfT"
      },
      "outputs": [],
      "source": [
        "def reduce_labels(xs,qs,ys,to_drop):\n",
        "    new_x=[]\n",
        "    new_q=[]\n",
        "    new_y=[]\n",
        "    to_keep = []\n",
        "    for name in labels:\n",
        "        if name not in to_drop:\n",
        "            idx = label_to_index(name)\n",
        "            to_keep.append(idx)\n",
        "    for x,q,y in zip(xs,qs,ys):\n",
        "        idx = np.where(y == 1)\n",
        "        name = index_to_label(idx[0][0])\n",
        "        if name not in to_drop:\n",
        "            new_x.append(x)\n",
        "            new_q.append(q)\n",
        "            new_y.append(y)\n",
        "        \n",
        "    new_y = np.array(new_y)\n",
        "    new_y = new_y[:,to_keep]\n",
        "    return np.array(new_x),np.array(new_q),new_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_5VJ3nMDV7t"
      },
      "source": [
        "# 18. Print label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doqoH9mgObim"
      },
      "outputs": [],
      "source": [
        "print(len(labels))\n",
        "print(labels)\n",
        "print(np.sum(y_train,axis=0))\n",
        "print(np.sum(y_valid,axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zwTJHKUER4G"
      },
      "source": [
        "# 19. Reduce number of datapoints to make equally distributed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aU1lrDPc9sW"
      },
      "outputs": [],
      "source": [
        "amount = 134\n",
        "x_train, q_train, y_train = reduce_data(x_train, q_train, y_train, amount)\n",
        "x_valid, q_valid, y_valid = reduce_data(x_valid, q_valid, y_valid, amount)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eeUMlMLkvFy"
      },
      "source": [
        "# 20. Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfJn95VC0b6W"
      },
      "outputs": [],
      "source": [
        "def fit_model(model,trainx,trainy,valx,valy,check):\n",
        "    history = model.fit(\n",
        "        x=trainx, \n",
        "        y=trainy[0:trainx.shape[0],:],\n",
        "        epochs=EPOCHS, \n",
        "        callbacks=[check], \n",
        "        batch_size=BATCH_SIZE, \n",
        "        validation_data=(valx,valy[0:valx.shape[0],:])\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "## For Quanv Exp.\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
        "                           verbose=1, patience=10, min_delta=0.0001)\n",
        "\n",
        "checkpoint = ModelCheckpoint('/some_models/best_classic_reduced.hdf5', monitor='val_accuracy', \n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "qcnn_checkpoint = ModelCheckpoint('/some_models/best_qcnn_reduced.hdf5', monitor='val_accuracy', \n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "'''\n",
        "qcnn_kernel2_checkpoint = ModelCheckpoint('/some_models/best_qcnn_kernel2_time_test.hdf5', monitor='val_accuracy', \n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "conv_checkpoint = ModelCheckpoint('/some_models/best_conv_time_test.hdf5', monitor='val_accuracy', \n",
        "                             verbose=1, save_best_only=True, mode='max')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGel9ujC_o3L"
      },
      "source": [
        "# 21. Make results persistent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bge4VlvI_ejX"
      },
      "outputs": [],
      "source": [
        "seed = 1337       #0.9236871004104614 / 0.9225929975509644\n",
        "#seed = 42        #0.9280634522438049 / 0.8864879608154297\n",
        "#seed = 70770     #92.7 / 91.3\n",
        "#seed = 70110     #89.6 / 90.2\n",
        "#seed = 7734      #0.916301965713501 / 0.937089741230011\n",
        "#seed = 1234      #93.5 / 90.8\n",
        "#seed = 4321      #94.3 / 92.5\n",
        "#seed = 2022      #93.3 / 89.7\n",
        "#seed = 4851      #0.9149343371391296 / 0.908369779586792\n",
        "#seed = 6817      #0.9070022106170654 / 0.912472665309906\n",
        "#seed = 2580      #0.9368162155151367 / 0.9239606261253357\n",
        "#seed = 9630      #0.8998906016349792 / 0.9217724204063416\n",
        "#seed = 777       #0.9376367330551147 / 0.9171225428581238\n",
        "#seed = 9154      #0.9392778873443604 / 0.908369779586792\n",
        "#seed = 1         #0.9373632669448853 / 0.9141137599945068\n",
        "#seed = 9999      #0.9261487722396851 / 0.886761486530304\n",
        "#seed = 6161      #0.9318927526473999 / 0.8894967436790466\n",
        "#seed = 8723654   #0.9138402342796326 / 0.8998906016349792\n",
        "#seed = 6548      #0.9275164008140564 / 0.9119256138801575\n",
        "#seed = 43        #0.9321662783622742 / 0.9031728506088257\n",
        "#seed = 3310      #0.925328254699707 / 0.9132932424545288\n",
        "#seed = 315       #0.904540479183197 / 0.9018052220344543\n",
        "#seed = 78857676  #0.9217724204063416 / 0.9165754914283752\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_random_seed(seed)\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbfkJBZa7Ohm"
      },
      "source": [
        "#22. Training of normal models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xsrqAsilklaR"
      },
      "outputs": [],
      "source": [
        "print('Dataset sizes: ',q_train.shape, q_valid.shape)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "model = attrnn_Model(x_train[0], y_train[0], False, 64, 1)\n",
        "model.summary()\n",
        "classic_hist = fit_model(model,x_train[0:q_train.shape[0],:,:,:],y_train[0:q_train.shape[0],:],x_valid[0:q_valid.shape[0],:,:,:],y_valid[0:q_valid.shape[0],:],checkpoint)\n",
        "\n",
        "model = attrnn_Model(q_train[0], y_train[0], False, 64, 1)\n",
        "model.summary()\n",
        "qcnn_hist = fit_model(model,q_train,y_train,q_valid,y_valid,qcnn_checkpoint)\n",
        "\n",
        "\n",
        "#np.save('/training_histories/classic_histFULL.npy', classic_hist.history)     #OK\n",
        "#np.save('/training_histories/qcnn_histFULL_ALTKERN.npy', qcnn_hist.history)   #OK\n",
        "#np.save('/training_histories/cconv_histFULL.npy', classic_hist.history)       #OK\n",
        "#np.save('/training_histories/qcnn_histFULL.npy', qcnn_hist.history)           #OK\n",
        "#np.save('/training_histories/classic_hist.npy', classic_hist.history)         #OK\n",
        "#np.save('/training_histories/qcnn_hist.npy', qcnn_hist.history)               #OK\n",
        "#np.save('/training_histories/cconv_hist.npy', classic_hist.history)           #OK\n",
        "#np.save('/training_histories/classic_histTENCLASS.npy', classic_hist.history) #OK\n",
        "#np.save('/training_histories/qcnn_histTENCLASS.npy', qcnn_hist.history)       #OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRND6mGJjbIG"
      },
      "source": [
        "# 23. Timing of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z26dx2AmjZTP"
      },
      "outputs": [],
      "source": [
        "print('Dataset sizes: ',q_train.shape, q_valid.shape)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "times = []\n",
        "start = ti.time()\n",
        "\n",
        "model = attrnn_Model(x_train[0], labels, False, 64, 1)\n",
        "model.summary()\n",
        "classic_hist = fit_model(model,x_train,y_train,x_valid,y_valid,checkpoint)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "model = attrnn_Model(q_train[0], labels, False, 64, 1)\n",
        "model.summary()\n",
        "qcnn_hist = fit_model(model,q_train,y_train,q_valid,y_valid,qcnn_checkpoint)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "model = attrnn_Model(q_train2[0], labels, False, 64, 1)\n",
        "model.summary()\n",
        "qcnn2_hist = fit_model(model,q_train2,y_train,q_valid2,y_valid,qcnn_kernel2_checkpoint)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "model = attrnn_Model(c_train[0], labels, False, 64, 1)\n",
        "model.summary()\n",
        "conv_hist = fit_model(model,c_train,y_train,c_valid,y_valid,conv_checkpoint)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "print(times)\n",
        "np.save('/training_histories/classic_hist_timed.npy', classic_hist.history)               #OK\n",
        "np.save('/training_histories/qcnn_hist_timed.npy', qcnn_hist.history)           #OK\n",
        "np.save('/training_histories/qcnn2_hist_timed.npy', qcnn2_hist.history) #OK\n",
        "np.save('/training_histories/conv_hist_timed.npy', conv_hist.history)       #OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLmAqUkMned-"
      },
      "outputs": [],
      "source": [
        "classic_model = load_model('/some_models/best_classic_time_test.hdf5')\n",
        "qcnn_model = load_model('/some_models/best_qcnn_time_test.hdf5')\n",
        "qcnn2_model = load_model('/some_models/best_qcnn_kernel2_time_test.hdf5')\n",
        "conv_model = load_model('/some_models/best_conv_time_test.hdf5')\n",
        "\n",
        "times = []\n",
        "start = ti.time()\n",
        "classic_predict = classic_model.predict(x_valid,16)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "qcnn_predict = qcnn_model.predict(q_valid,16)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "qcnn2_predict = qcnn2_model.predict(q_valid2,16)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "start = ti.time()\n",
        "conv_predict = conv_model.predict(c_valid,16)\n",
        "times.append(ti.time() - start)\n",
        "\n",
        "print(times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xXkRbA7ojfJ"
      },
      "source": [
        "# 24. Create confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7jBXj9Blisa"
      },
      "outputs": [],
      "source": [
        "def conf(yarr,predarr):\n",
        "    conf_matrix = [[0 for i in range(yarr.shape[1])] for j in range(predarr.shape[1])]\n",
        "    for y,pred in zip(yarr,predarr):\n",
        "        max_y = max(y)\n",
        "        max_pred = max(pred)\n",
        "        idx_y = np.where(y == max_y)[0][0]\n",
        "        idx_pred = np.where(pred == max_pred)[0][0]\n",
        "        conf_matrix[idx_y][idx_pred] += 1\n",
        "    \n",
        "    return conf_matrix    \n",
        "\n",
        "def get_predictions(model,data):\n",
        "    predict = model.predict(data,16)\n",
        "    \n",
        "    return predict\n",
        "    \n",
        "def get_df(matrix, labels):\n",
        "    df = pd.DataFrame(matrix, index = [i for i in labels],columns = [i for i in labels])\n",
        "    \n",
        "    return df\n",
        "\n",
        "def plot_heatmap(df,title):\n",
        "    plt.figure(figsize = (20,10))\n",
        "    sn.heatmap(df, annot=True, fmt='g')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "classic_model = load_model('/some_models/best_classic_reduced.hdf5')\n",
        "qcnn_model = load_model('/some_models/best_qcnn_reduced.hdf5')\n",
        "\n",
        "classic_predict = get_predictions(classic_model,x_valid)\n",
        "qcnn_predict = get_predictions(qcnn_model,q_valid)\n",
        "\n",
        "classic_conf_matrix = conf(y_valid,classic_predict)\n",
        "qcnn_conf_matrix = conf(y_valid,qcnn_predict)\n",
        "\n",
        "df_classic = get_df(classic_conf_matrix,labels)\n",
        "df_qcnn = get_df(qcnn_conf_matrix,labels)\n",
        "\n",
        "print(classic_conf_matrix)\n",
        "print(qcnn_conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nKsYvvQn2xmG"
      },
      "outputs": [],
      "source": [
        "plot_heatmap(df_classic,'Classic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ8wHbnw20k3"
      },
      "outputs": [],
      "source": [
        "plot_heatmap(df_qcnn,'Quanvolved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGJ8OhHXpBwc"
      },
      "outputs": [],
      "source": [
        "diagonal = np.diag(classic_conf_matrix)\n",
        "qdiagonal = np.diag(qcnn_conf_matrix)\n",
        "\n",
        "column_sums = np.sum(classic_conf_matrix, axis=0)\n",
        "row_sums = np.sum(classic_conf_matrix, axis=1)\n",
        "qcolumn_sums = np.sum(qcnn_conf_matrix, axis=0)\n",
        "qrow_sums = np.sum(qcnn_conf_matrix, axis=1)\n",
        "\n",
        "column_sums -= diagonal\n",
        "row_sums -= diagonal\n",
        "qcolumn_sums -= qdiagonal\n",
        "qrow_sums -= qdiagonal\n",
        "\n",
        "print('Classic false positive',column_sums,sum(column_sums))\n",
        "print('Quantum false positive',qcolumn_sums,sum(qcolumn_sums))\n",
        "print('Combined false positives',column_sums+qcolumn_sums)\n",
        "\n",
        "cerrors = column_sums+row_sums\n",
        "ctotal = column_sums+row_sums+diagonal\n",
        "qerrors = qcolumn_sums+qrow_sums\n",
        "qtotal = qcolumn_sums+qrow_sums+qdiagonal\n",
        "\n",
        "total_errors = (cerrors+qerrors) / (cerrors+qerrors+ctotal+qtotal)\n",
        "min_error = min(total_errors)\n",
        "min_id = np.where(total_errors == min_error)[0][0]\n",
        "\n",
        "to_drop = [labels[min_id]]\n",
        "new_labels = []\n",
        "for lbl in labels:\n",
        "  if lbl not in to_drop:\n",
        "    new_labels.append(lbl)\n",
        "\n",
        "new_labels = np.array(new_labels)\n",
        "np.save('/datasets/new_labels', new_labels)\n",
        "\n",
        "\n",
        "x_train, q_train, y_train = reduce_labels(x_train, q_train, y_train, to_drop)\n",
        "x_valid, q_valid, y_valid = reduce_labels(x_valid, q_valid, y_valid, to_drop)\n",
        "\n",
        "np.save('/datasets/x_trainREDUCED.npy', x_train)\n",
        "np.save('/datasets/x_validREDUCED.npy', x_valid)\n",
        "np.save('/datasets/q_trainREDUCED.npy', q_train)\n",
        "np.save('/datasets/q_validREDUCED.npy', q_valid)\n",
        "np.save('/datasets/y_trainREDUCED.npy', y_train)\n",
        "np.save('/datasets/y_validREDUCED.npy', y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-iArju_CqC0"
      },
      "outputs": [],
      "source": [
        "print(to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YhOKGRR1zHs"
      },
      "outputs": [],
      "source": [
        "save = {}\n",
        "commands = len(labels)\n",
        "save['commands'] = commands\n",
        "save['classic_max'] = max(classic_hist.history['val_accuracy'])\n",
        "save['qcnn_max'] = max(qcnn_hist.history['val_accuracy'])\n",
        "save[f'classic_{commands}'] = classic_conf_matrix\n",
        "save[f'qcnn_{commands}'] = qcnn_conf_matrix\n",
        "save['to_drop'] = to_drop\n",
        "np.save(f'/label_reduce_results/{commands}_tot_err.npy', save)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsX_ND0QQ8Ie"
      },
      "source": [
        "# 25. Plot normal model training loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Az9WNWw_a6e"
      },
      "outputs": [],
      "source": [
        "#Load saved training histories\n",
        "import numpy as np\n",
        "classic_hist = np.load('/datasets/classic_histTENCLASS.npy',allow_pickle='TRUE').item()\n",
        "qcnn_hist = np.load('/datasets/qcnn_histTENCLASS.npy',allow_pickle='TRUE').item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg-u5rM1Q_Le"
      },
      "outputs": [],
      "source": [
        "data_ix = ti.strftime(\"%m%d_%H%M\")\n",
        "linestyle_arr = ['solid', 'dotted', 'dashed', 'dashdot', (0, (3, 5, 1, 5, 1, 5))]\n",
        "\n",
        "def plot_acc_loss(points, x_history, q_history, data_ix, x_label, q_label):\n",
        "    plt.figure()\n",
        "    plt.style.use(\"seaborn\")\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
        "\n",
        "    ax1.plot(q_history[\"val_accuracy\"], linestyle=linestyle_arr[0], linewidth=1.5, color='b', label=q_label)\n",
        "    ax1.plot(x_history[\"val_accuracy\"], linestyle=linestyle_arr[1], linewidth=1.5, color='g', label=x_label)\n",
        "    ax1.set_ylabel(\"Accuracy\")\n",
        "    ax1.set_ylim([0, 1])\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(q_history[\"val_loss\"], linestyle=linestyle_arr[0], linewidth=1.5, color='b', label=q_label)\n",
        "    ax2.plot(x_history[\"val_loss\"], linestyle=linestyle_arr[1], linewidth=1.5, color='g', label=x_label)\n",
        "    ax2.set_ylabel(\"Loss\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax2.legend()\n",
        "    plt.title('Number of datapoints: '+str(points))\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/Old_plots/\"+ data_ix +\"_conv_speech_loss.png\")\n",
        "\n",
        "def show_speech(x_train, q_train, use_ch):\n",
        "    plt.figure()\n",
        "    plt.subplot(5, 1, 1)\n",
        "    if use_ch != True:\n",
        "        librosa.display.specshow(librosa.power_to_db(x_train[7088,:,:,0], ref=np.max))\n",
        "    else:\n",
        "        librosa.display.specshow(librosa.power_to_db(x_train[0,:,:], ref=np.max))\n",
        "    plt.title('Input Speech')\n",
        "\n",
        "    for i in range(4):\n",
        "        plt.subplot(5, 1, i+2)\n",
        "        librosa.display.specshow(librosa.power_to_db(q_train[7088,:,:,i], ref=np.max))\n",
        "        plt.title('Channel '+str(i+1)+': Quantum Compressed Speech')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/Old_plots/speech_encoder_\" + data_ix + \".png\")\n",
        "\n",
        "# Set legends for plot\n",
        "x_label = \"Attn-BiLSTM without Quanv Layer\"\n",
        "q_label = \"Attn-BiLSTM with Quanv Layer\"\n",
        "\n",
        "plot_acc_loss(10000,classic_hist.history, qcnn_hist.history, data_ix, x_label, q_label)\n",
        "#show_speech(x_train,q_train, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhDRecBbD1ES"
      },
      "source": [
        "# 26. Print max and mean validation accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggh_BgKY2Sym"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "print('Max acc classic:',np.max(classic_hist.history[\"val_accuracy\"]))\n",
        "print('Avg acc classic:',np.average(classic_hist.history[\"val_accuracy\"]))\n",
        "print('Standard error of the mean:',stats.sem(classic_hist.history[\"val_accuracy\"]))\n",
        "print('Max acc quantum:',np.max(qcnn_hist.history[\"val_accuracy\"]))\n",
        "print('Avg acc quantum:',np.average(qcnn_hist.history[\"val_accuracy\"]))\n",
        "print('Standard error of the mean:',stats.sem(qcnn_hist.history[\"val_accuracy\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozBFU7yVqZQJ"
      },
      "source": [
        "# 27. Function to reduce data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQZAT2yvimQY"
      },
      "outputs": [],
      "source": [
        "def reduce_data(x,q,y,to_amount):\n",
        "    label_dict = {'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0, 'down':0, 'eight':0, 'five':0, 'follow':0, 'forward':0, 'four':0, 'go':0, 'happy':0, 'house':0, 'learn':0, 'left':0, 'marvin':0, 'nine':0, 'no':0, 'off':0, 'on':0, 'one':0, 'right':0, 'seven':0, 'sheila':0, 'six':0, 'stop':0, 'three':0, 'tree':0, 'two':0, 'up':0, 'visual':0, 'wow':0, 'yes':0, 'zero':0}\n",
        "    ret_x = []\n",
        "    ret_q = []\n",
        "    ret_y = []\n",
        "    for classic, quantum, lbl in zip(x,q,y):\n",
        "      idx = np.where(lbl == 1)\n",
        "      name = index_to_label(idx[0][0])\n",
        "      amount = label_dict[name]\n",
        "      if amount < to_amount:\n",
        "        ret_x.append(classic)\n",
        "        ret_q.append(quantum)\n",
        "        ret_y.append(lbl)\n",
        "        label_dict[name] += 1\n",
        "\n",
        "    return np.array(ret_x), np.array(ret_q), np.array(ret_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAuNRS6YCeJo"
      },
      "source": [
        "# 28. Equalize dataset and introduce some helper variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTycCemGCctr"
      },
      "outputs": [],
      "source": [
        "x_train = x_train[0:q_train.shape[0],:,:,:]\n",
        "y_train = y_train[0:q_train.shape[0],:]\n",
        "x_valid = x_valid[0:q_valid.shape[0],:,:,:]\n",
        "y_valid = y_valid[0:q_valid.shape[0],:]\n",
        "ind = 0\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G79NduKY1Am4"
      },
      "source": [
        "# 29. Training models with reduced datapoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrWvkPbGqhmx"
      },
      "outputs": [],
      "source": [
        "amount = 22\n",
        "div = 1\n",
        "xtrain, qtrain, ytrain = reduce_data(x_train, q_train, y_train, amount)\n",
        "\n",
        "model = attrnn_Model(xtrain[0], labels, False, 64, div)\n",
        "classic_hist = fit_model(model,xtrain,ytrain,x_valid,y_valid,checkpoint).history\n",
        "\n",
        "model = attrnn_Model(qtrain[0], labels, False, 64, div)\n",
        "qcnn_hist = fit_model(model,qtrain,ytrain,q_valid,y_valid,qcnn_checkpoint).history\n",
        "\n",
        "np.save(f\"/datasets/classic_hist_{amount}_DATA_REDUCE_FULL.npy\", classic_hist)\n",
        "np.save(f\"/datasets/qcnn_hist_{amount}_DATA_REDUCE_FULL.npy\", qcnn_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKx6rftF1JiX"
      },
      "source": [
        "# 30. Plotting results from data reduced model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R6v8Wpc1OL_"
      },
      "outputs": [],
      "source": [
        "data_ix = ti.strftime(\"%m%d_%H%M\")\n",
        "linestyle_arr = ['solid', 'dotted', 'dashed', 'dashdot', (0, (3, 5, 1, 5, 1, 5))]\n",
        "color = ['b','g','r','c','m','y','k']\n",
        "\n",
        "def plot_acc_loss(points, x_history_arr, q_history_arr, data_ix, x_label, q_label):\n",
        "    plt.figure()\n",
        "    plt.style.use(\"seaborn\")\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 9))\n",
        "\n",
        "    for x_history, q_history, data, linestyle,col in zip(x_history_arr, q_history_arr, points, linestyle_arr,color):\n",
        "        ax1.plot(x_history[\"val_accuracy\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of datapoints '+str(data))\n",
        "        ax1.set_title(x_label)\n",
        "        ax1.set_ylabel(\"Accuracy\")\n",
        "        ax1.set_ylim([0, 1])\n",
        "        ax1.set_xlabel(\"Epoch\")\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(q_history[\"val_accuracy\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of datapoints '+str(data))\n",
        "        ax2.set_title(q_label)\n",
        "        ax2.set_ylabel(\"Accuracy\")\n",
        "        ax2.set_ylim([0, 1])\n",
        "        ax2.set_xlabel(\"Epoch\")\n",
        "        ax2.legend()\n",
        "\n",
        "        ax3.plot(x_history[\"val_loss\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of datapoints '+str(data))\n",
        "        ax3.set_ylabel(\"Loss\")\n",
        "        ax3.set_ylim([0, 8])\n",
        "        ax3.set_xlabel(\"Epoch\")\n",
        "        ax3.legend()\n",
        "        \n",
        "        ax4.plot(q_history[\"val_loss\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of datapoints '+str(data))\n",
        "        ax4.set_ylabel(\"Loss\")\n",
        "        ax4.set_ylim([0, 8])\n",
        "        ax4.set_xlabel(\"Epoch\")\n",
        "        ax4.legend()\n",
        "\n",
        "    plt.title('Training models and reducing number of datapoints')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/Old_plots/\"+ data_ix +\"_conv_speech_loss.png\")\n",
        "\n",
        "x_label = \"Attn-BiLSTM without Quanv Layer\"\n",
        "q_label = \"Attn-BiLSTM with Quanv Layer\"\n",
        "\n",
        "plot_acc_loss(data_size, classic_hist_arr, qcnn_hist_arr, data_ix, x_label, q_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhx0kPefCPm6"
      },
      "source": [
        "# 31. Train models while reducing model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFqH0vnrCMET"
      },
      "outputs": [],
      "source": [
        "div_arr = [2,4,8,12,16]\n",
        "div = 16\n",
        "\n",
        "model = attrnn_Model(x_train[0], labels, False, 47, div)\n",
        "model.summary()\n",
        "\n",
        "classic_hist = fit_model(model,x_train,y_train,x_valid,y_valid,checkpoint).history\n",
        "classic_weights = count_params(model.trainable_weights)\n",
        "\n",
        "model = attrnn_Model(q_train[0], labels, False, 64, div)\n",
        "model.summary()\n",
        "\n",
        "qcnn_hist = fit_model(model,q_train,y_train,q_valid,y_valid,qcnn_checkpoint).history\n",
        "qcnn_weights = count_params(model.trainable_weights)\n",
        "\n",
        "np.save(f\"/datasets/classic_hist_{classic_weights}_PARAM_REDUCE_FULL.npy\", classic_hist)\n",
        "np.save(f\"/datasets/qcnn_hist_{qcnn_weights}_PARAM_REDUCE_FULL.npy\", qcnn_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEE72G3zDOH4"
      },
      "source": [
        "# 32. Plotting data from parameter reduced model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smkBH1zADLzy"
      },
      "outputs": [],
      "source": [
        "data_ix = ti.strftime(\"%m%d_%H%M\")\n",
        "linestyle_arr = ['solid', 'dotted', 'dashed', 'dashdot', (0, (3, 5, 1, 5, 1, 5)))]\n",
        "color = ['b','g','r','c','m','y','k']\n",
        "def plot_acc_loss(cpoints, qpoints, x_history_arr, q_history_arr, data_ix, x_label, q_label):\n",
        "    plt.figure()\n",
        "    plt.style.use(\"seaborn\")\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 9))\n",
        "\n",
        "    for x_history, q_history, c_data, q_data, linestyle,col in zip(x_history_arr, q_history_arr, cpoints, qpoints, linestyle_arr,color):\n",
        "        ax1.plot(x_history.history[\"val_accuracy\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of parameters '+str(c_data))\n",
        "        ax1.set_title(x_label)\n",
        "        ax1.set_ylabel(\"Accuracy\")\n",
        "        ax1.set_ylim([0, 1])\n",
        "        ax1.set_xlabel(\"Epoch\")\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(q_history.history[\"val_accuracy\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of parameters '+str(q_data))\n",
        "        ax2.set_title(q_label)\n",
        "        ax2.set_ylabel(\"Accuracy\")\n",
        "        ax2.set_ylim([0, 1])\n",
        "        ax2.set_xlabel(\"Epoch\")\n",
        "        ax2.legend()\n",
        "\n",
        "        ax3.plot(x_history.history[\"val_loss\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of parameters '+str(c_data))\n",
        "        ax3.set_ylabel(\"Loss\")\n",
        "        ax3.set_ylim([0, 8])\n",
        "        ax3.set_xlabel(\"Epoch\")\n",
        "        ax3.legend()\n",
        "        \n",
        "        ax4.plot(q_history.history[\"val_loss\"], linestyle=linestyle, linewidth=1.5, color=col, label='Number of parameters '+str(q_data))\n",
        "        ax4.set_ylabel(\"Loss\")\n",
        "        ax4.set_ylim([0, 8])\n",
        "        ax4.set_xlabel(\"Epoch\")\n",
        "        ax4.legend()\n",
        "\n",
        "    plt.title('Training models and reducing number of parameters')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/Old_plots/\"+ data_ix +\"_conv_speech_loss.png\")\n",
        "\n",
        "x_label = \"Attn-BiLSTM without Quanv Layer\"\n",
        "q_label = \"Attn-BiLSTM with Quanv Layer\"\n",
        "\n",
        "plot_acc_loss(c_num_param, q_num_param, classic_hist_arr, qcnn_hist_arr, data_ix, x_label, q_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoKKn4-9FOTT"
      },
      "source": [
        "# 33. Print max and mean validation accuracies for data and parameter reduced models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VFSuR9kCncq"
      },
      "outputs": [],
      "source": [
        "for classic,quantum in zip(classic_hist_arr,qcnn_hist_arr):\n",
        "    print('Max acc classic:',np.max(classic[\"val_accuracy\"]))\n",
        "    print('Avg acc classic:',np.average(classic[\"val_accuracy\"]))\n",
        "    print('Max acc quantum:',np.max(quantum[\"val_accuracy\"]))\n",
        "    print('Avg acc quantum:',np.average(quantum[\"val_accuracy\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WRb7j7dpDp_"
      },
      "source": [
        "#34. Quanvolution helper function for mock up data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXKnsxan0wlZ"
      },
      "outputs": [],
      "source": [
        "def gen_qspeech_no_save(x_train, kr):\n",
        "    q_train = []\n",
        "    \n",
        "    for idx, img in enumerate(x_train):\n",
        "        params = np.random.uniform(low=0, high=2*np.pi, size=(4, 3))\n",
        "        q_train.append(conv(img, kr))\n",
        "    \n",
        "    return np.asarray(q_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ErSJ_KpPkd"
      },
      "source": [
        "# 35. Mock up data to test result of quanvolution of simple binary image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McrdP8ctzt6P"
      },
      "outputs": [],
      "source": [
        "simple_img = [[[0,0],[0,0]],\n",
        "              [[1,0],[0,0]],\n",
        "              [[0,1],[0,0]],\n",
        "              [[0,0],[1,0]],\n",
        "              [[0,0],[0,1]],\n",
        "              [[1,1],[0,0]],\n",
        "              [[1,0],[1,0]],\n",
        "              [[1,0],[0,1]],\n",
        "              [[0,1],[1,0]],\n",
        "              [[0,1],[0,1]],\n",
        "              [[0,0],[1,1]],\n",
        "              [[1,1],[1,0]],\n",
        "              [[1,1],[0,1]],\n",
        "              [[0,1],[1,1]],\n",
        "              [[1,0],[1,1]],\n",
        "              [[1,1],[1,1]]]\n",
        "\n",
        "simple_img = np.array(simple_img)\n",
        "simple_img = simple_img.reshape(simple_img.shape[0],2,2,1)\n",
        "\n",
        "'''\n",
        "param_arr = [[0,0,0],\n",
        "             [2*np.pi,2*np.pi,2*np.pi],\n",
        "             [2*np.pi,2*np.pi,0],\n",
        "             [0,0,2*np.pi],\n",
        "             [0,2*np.pi,0],\n",
        "             [2*np.pi,0,2*np.pi],\n",
        "             [2*np.pi,0,0],\n",
        "             [0,2*np.pi,2*np.pi],\n",
        "             [np.pi,0,np.pi],\n",
        "             [np.pi,2*np.pi,np.pi],\n",
        "             [0,np.pi,np.pi],\n",
        "             [2*np.pi,np.pi,np.pi],\n",
        "             [np.pi,np.pi,2*np.pi],\n",
        "             [np.pi,np.pi,0]]\n",
        "'''\n",
        "'''\n",
        "param_arr = [[0.5*np.pi,0.5*np.pi,0.5*np.pi],\n",
        "             [1.5*np.pi,1.5*np.pi,1.5*np.pi],\n",
        "             [1.5*np.pi,1.5*np.pi,0.5*np.pi],\n",
        "             [0.5*np.pi,0.5*np.pi,1.5*np.pi],\n",
        "             [0.5*np.pi,1.5*np.pi,0.5*np.pi],\n",
        "             [1.5*np.pi,0.5*np.pi,1.5*np.pi],\n",
        "             [1.5*np.pi,0.5*np.pi,0.5*np.pi],\n",
        "             [0.5*np.pi,1.5*np.pi,1.5*np.pi],\n",
        "             [np.pi,0.5*np.pi,np.pi],\n",
        "             [np.pi,1.5*np.pi,np.pi],\n",
        "             [0.5*np.pi,np.pi,np.pi],\n",
        "             [1.5*np.pi,np.pi,np.pi],\n",
        "             [np.pi,np.pi,1.5*np.pi],\n",
        "             [np.pi,np.pi,0.5*np.pi]]\n",
        "'''\n",
        "\n",
        "unqs = []\n",
        "unqs = np.asarray(unqs)\n",
        "best = 0\n",
        "best_params = []\n",
        "for ind in range(10000000):\n",
        "    params = np.random.uniform(low=0, high=2*np.pi, size=(4, 3))\n",
        "    simple_q = gen_qspeech_no_save(simple_img,2)\n",
        "    simple_q = np.around(simple_q, 2)\n",
        "    cur = np.unique(simple_q).shape[0]\n",
        "    if cur >= best:\n",
        "      if cur > best:\n",
        "        best_params = []\n",
        "        unqs = []\n",
        "        unqs = np.asarray(unqs)\n",
        "        best = cur\n",
        "\n",
        "      best_params.append(params)\n",
        "      unqs = np.append(unqs,cur)\n",
        "      best_params = np.asarray(best_params)\n",
        "      np.save('/datasets/best_params.npy',best_params)\n",
        "      best_params = best_params.tolist()\n",
        "      np.save('/datasets/unqs.npy',unqs)\n",
        "        \n",
        "'''\n",
        "for a in param_arr: \n",
        "  for b in param_arr:\n",
        "    for c in param_arr:\n",
        "      for d in param_arr:\n",
        "        params = [a,b,c,d]\n",
        "        simple_q = gen_qspeech_no_save(simple_img,2)\n",
        "        simple_q = np.around(simple_q, 2)\n",
        "        cur = np.unique(simple_q).shape[0]\n",
        "        if cur > best:\n",
        "          best = cur\n",
        "          best_params.append([a,b,c,d])\n",
        "        \n",
        "        unqs.append(cur)\n",
        "'''\n",
        "\n",
        "for img in simple_q:\n",
        "  print(img)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZHHW2u7TB8C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "best_params = np.load('/datasets/best_params.npy')\n",
        "unqs = np.load('/datasets/unqs.npy')\n",
        "#params = best_params[4]\n",
        "\n",
        "simple_img = [[[0,0],[0,0]],\n",
        "              [[1,0],[0,0]],\n",
        "              [[0,1],[0,0]],\n",
        "              [[0,0],[1,0]],\n",
        "              [[0,0],[0,1]],\n",
        "              [[1,1],[0,0]],\n",
        "              [[1,0],[1,0]],\n",
        "              [[1,0],[0,1]],\n",
        "              [[0,1],[1,0]],\n",
        "              [[0,1],[0,1]],\n",
        "              [[0,0],[1,1]],\n",
        "              [[1,1],[1,0]],\n",
        "              [[1,1],[0,1]],\n",
        "              [[0,1],[1,1]],\n",
        "              [[1,0],[1,1]],\n",
        "              [[1,1],[1,1]]]\n",
        "\n",
        "simple_img = np.array(simple_img)\n",
        "simple_img = simple_img.reshape(simple_img.shape[0],2,2,1)\n",
        "\n",
        "simple_q = gen_qspeech_no_save(simple_img,2)\n",
        "simple_q = np.around(simple_q, 2)\n",
        "print(np.unique(simple_q).shape[0])\n",
        "print(simple_q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP5CAXQ3wuIw"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "\n",
        "for x,y,z in best_params[4]:\n",
        "    xs.append(x)\n",
        "    ys.append(y)\n",
        "    zs.append(z)\n",
        "\n",
        "ax.scatter(xs, ys, zs)\n",
        "ax.axes.set_xlim3d(left=0, right=2*np.pi) \n",
        "ax.axes.set_ylim3d(bottom=0, top=2*np.pi) \n",
        "ax.axes.set_zlim3d(bottom=0, top=2*np.pi) \n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Qm4aCQp_n5dd",
        "uKiVmhI5TelQ",
        "Jvma096dTq4e",
        "ctaXwnxa2OfE",
        "gr4UHf9c4Wb5",
        "zs9p3x-iuGaa",
        "N_HhUF1GutNv",
        "f5xXnan73TD3",
        "bKRiIGJ53qdv",
        "5RREPFMN4EQN",
        "2qQxxbYj2kLg",
        "FhTsYGF52pi0",
        "G9WEFUrJC5Ug",
        "Z9WfGQUHluTW",
        "D9KLO4QO3djn",
        "A_ti0sx73gko",
        "LiuyFwYQDzrx",
        "m5m3Mh68D8I4",
        "PE86hgD8pcOE",
        "5e-HsngY3ZV-",
        "0zwTJHKUER4G",
        "CRND6mGJjbIG",
        "jhDRecBbD1ES",
        "rAuNRS6YCeJo",
        "G79NduKY1Am4",
        "yKx6rftF1JiX",
        "rhx0kPefCPm6",
        "YEE72G3zDOH4",
        "UoKKn4-9FOTT",
        "0WRb7j7dpDp_",
        "F1ErSJ_KpPkd"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}